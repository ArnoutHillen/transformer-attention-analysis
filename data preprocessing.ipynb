{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data preprocessing.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1z5icyDLmelfD_P_MofrHgG7HOmdEzvJH","authorship_tag":"ABX9TyMI54gC4Z0EpFgqr4P/CK04"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2c47860a73574aa880ff8413f9f02055":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_759c0817890948a2b5322abc822e490e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f70d697376144ee28da179fd85632e19","IPY_MODEL_6a5f47c90d9246fa8be96601698bc32c"]}},"759c0817890948a2b5322abc822e490e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f70d697376144ee28da179fd85632e19":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fdee922a701841b7944644737c77b0f8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e3d86eac15e46a4bc714b7c3dfeb3ca"}},"6a5f47c90d9246fa8be96601698bc32c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f266fc6956fc4020be8ad7b0d39f4473","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 1.28kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04393b4d7c9845328ff09812789baa73"}},"fdee922a701841b7944644737c77b0f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6e3d86eac15e46a4bc714b7c3dfeb3ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f266fc6956fc4020be8ad7b0d39f4473":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"04393b4d7c9845328ff09812789baa73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"34a3315142a44bb284fcf8d67a8e2a6b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ce68e6c007be470f8301db28de648e9e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ce768037568d4e17a5feb4e34a26bc6d","IPY_MODEL_446f214aad8c440da2c37f070d1aaabd"]}},"ce68e6c007be470f8301db28de648e9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce768037568d4e17a5feb4e34a26bc6d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_769dd33ac7fd497693c3c40ad955aeae","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":435779157,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435779157,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5eae51b780604a82b03cb5e76af2d015"}},"446f214aad8c440da2c37f070d1aaabd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ed6dca13e1e74a65b8f59e79b74883a6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 436M/436M [00:24&lt;00:00, 17.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33179b70557e4dfca79335d199819cda"}},"769dd33ac7fd497693c3c40ad955aeae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5eae51b780604a82b03cb5e76af2d015":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed6dca13e1e74a65b8f59e79b74883a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"33179b70557e4dfca79335d199819cda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6abbe54a29c04bfa84603ff882a7f0a5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_06d8de1426ac4327bc00bf12c31b44c1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_05d60d7ae5ad433681421786e38ae4ce","IPY_MODEL_9263629278da4bd495ed547dbf7db3ff"]}},"06d8de1426ac4327bc00bf12c31b44c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"05d60d7ae5ad433681421786e38ae4ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_98c70d73b3e54e509bded8ade6453720","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_07e8162a766e46a9831a3df9ca0e1a9f"}},"9263629278da4bd495ed547dbf7db3ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_51dd6529c6cd4ad3b0334a5680aaded3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 213k/213k [00:00&lt;00:00, 501kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_71ad220c93fd47f9841c309b534d7f38"}},"98c70d73b3e54e509bded8ade6453720":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"07e8162a766e46a9831a3df9ca0e1a9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51dd6529c6cd4ad3b0334a5680aaded3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"71ad220c93fd47f9841c309b534d7f38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gArp1RaUNxb6","executionInfo":{"status":"ok","timestamp":1608044338125,"user_tz":-60,"elapsed":32444,"user":{"displayName":"Arnout Hillen","photoUrl":"","userId":"08191576707558497951"}},"outputId":"2d6e4ba4-f5ab-455f-eb79-b5bf760b35d0"},"source":["!pip -q install datasets sentencepiece  \n","!pip -q install git+https://github.com/ArnoutHillen/transformers.git # contains the modified transformers (returns the value vectors)\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 163kB 7.4MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 11.6MB/s \n","\u001b[K     |████████████████████████████████| 245kB 20.6MB/s \n","\u001b[K     |████████████████████████████████| 17.7MB 208kB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 2.9MB 8.2MB/s \n","\u001b[K     |████████████████████████████████| 890kB 32.8MB/s \n","\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8SQkA2nm6Kqr"},"source":["# Preprocessor classes"]},{"cell_type":"code","metadata":{"id":"ngbup1KrsrYn"},"source":["import numpy as np\n","import spacy\n","import torch\n","\n","from typing import List, Set, Dict, Optional\n","from datasets import load_from_disk\n","\n","from transformers import (\n","    PreTrainedTokenizer, PreTrainedModel,\n","    BertTokenizer, BertModel, \n","    GPT2Tokenizer, GPT2Model, \n","    XLNetTokenizer, XLNetModel, \n","    ElectraTokenizer, ElectraModel\n",")\n","\n","\n","class Preprocessor(object):\n","    \"\"\"\n","    The dataset should contain the following columns:\n","    - \"text\"\n","    \"\"\"\n","\n","    def __init__(self, model: PreTrainedModel, tokenizer: PreTrainedTokenizer,\n","                 special_tokens: Optional[Set[str]] = None,\n","                 allignment_mapping: Optional[Dict[str, str]] = None, pre_token_chs: Optional[str] = None,\n","                 nlp=spacy.load(\"en_core_web_sm\")):\n","        self.model = model\n","        self.tokenizer = tokenizer\n","        self.special_tokens = special_tokens if special_tokens is not None else set()\n","        self.allignment_mapping = allignment_mapping if allignment_mapping is not None else dict()\n","        self.pre_token_chs = pre_token_chs if pre_token_chs is not None else str()\n","        self.nlp = nlp\n","\n","    def allignment(self, model_tokens: List[str], spacy_tokens: List[str]) -> List[int]:\n","        allignment_list = [-1 for _ in range(len(model_tokens))]\n","        prev_i = -1\n","        for j, model_token in enumerate(model_tokens):\n","            t = model_token\n","            if t in self.special_tokens:\n","                continue\n","            else:\n","                if t[:len(self.pre_token_chs)] == self.pre_token_chs:\n","                    t = t[len(self.pre_token_chs):]\n","                if t in self.allignment_mapping.keys():\n","                    t = self.allignment_mapping[t]\n","                for i, spacy_token in enumerate(spacy_tokens):\n","                    if t in spacy_token and i >= prev_i:\n","                        spacy_index = i\n","                        prev_i = i\n","                        break\n","                allignment_list[j] = spacy_index\n","        return allignment_list\n","\n","    def add_tokens(self, example: dict) -> dict:\n","        inputs = self.tokenizer(example[\"text\"], return_tensors=\"pt\")\n","        return {\"tokens\": self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze())}\n","\n","    def add_attention(self, example: dict) -> dict:\n","        inputs = self.tokenizer(example[\"text\"], return_tensors=\"pt\")\n","        outputs = self.model(**inputs)\n","        attention = outputs[\"attentions\"]\n","        attention = torch.stack(attention).squeeze()\n","        return {\"attention\": attention.detach().numpy()}\n","\n","    def add_pos_tags(self, example: dict) -> dict:\n","        tokens = example[\"tokens\"]\n","        spacy_tokens = self.nlp(example[\"text\"])\n","        spacy_text_tokens = [token.text for token in spacy_tokens]\n","        allignment_list = self.allignment(tokens, spacy_text_tokens)\n","        spacy_pos_tags = [token.pos_ for token in spacy_tokens]\n","        pos_tags = [spacy_pos_tags[i] if i != -1 else \"-1\" for i in allignment_list]\n","        return {\"pos\": pos_tags}\n","\n","    def add_norms(self, example: dict) -> dict:\n","        inputs = self.tokenizer(example[\"text\"], return_tensors=\"pt\")\n","        outputs = self.model(**inputs)\n","        values = outputs[\"values\"]\n","        values = torch.stack(values).squeeze()\n","        values = values.detach().numpy()\n","        dense = outputs[\"dense\"]\n","        print(type(values))\n","        print(type(dense))\n","        norms = np.linalg.norm(values, axis=-1)\n","        return {\"norms\": norms}\n","\n","\n","class BertPreprocessorBase(Preprocessor):\n","    def __init__(self, model, tokenizer):\n","        super().__init__(\n","            model=model,\n","            tokenizer=tokenizer,\n","            special_tokens={\"[CLS]\", \"[SEP]\"},\n","            allignment_mapping={\n","                \"your\": \"you\",\n","                \"im\": \"i\",\n","                \"isn\": \"is\",\n","                \"don\": \"do\",\n","                \"aren\": \"are\",\n","                \"id\": \"i\",\n","                \"can\": \"ca\",\n","                \"iv\": \"i\"\n","            },\n","            pre_token_chs=\"##\",\n","        )\n","\n","\n","class BertPreprocessor(BertPreprocessorBase):\n","    def __init__(self):\n","        super().__init__(\n","            model=BertModel.from_pretrained(\"bert-base-cased\", output_attentions=True, output_values=True, output_dense=True),\n","            tokenizer=BertTokenizer.from_pretrained(\"bert-base-cased\"),\n","        )\n","\n","\n","class GPT2Preprocessor(Preprocessor):\n","    def __init__(self):\n","        super().__init__(\n","            model=GPT2Model.from_pretrained(\"gpt2\", output_attentions=True, output_values=True, output_dense=True),\n","            tokenizer=GPT2Tokenizer.from_pretrained(\"gpt2\"),\n","            special_tokens=None,\n","            allignment_mapping={\n","                \"didnt\": \"did\",\n","                \"hes\": \"he\",\n","                \"im\": \"i\",\n","                \"cant\": \"ca\",\n","                \"arent\": \"are\",\n","                \"id\": \"i\",\n","                \"ive\": \"i\"\n","            },\n","            pre_token_chs=\"Ġ\",\n","        )\n","\n","\n","class XLNetPreprocessor(Preprocessor):\n","    def __init__(self):\n","        super().__init__(\n","            model=XLNetModel.from_pretrained(\"xlnet-base-cased\", output_attentions=True, output_values=True),  #, output_dense=True),\n","            tokenizer=XLNetTokenizer.from_pretrained(\"xlnet-base-cased\"),\n","            special_tokens={\"<sep>\", \"<cls>\"},\n","            allignment_mapping={\n","                \"im\": \"i\",\n","                \"didn\": \"did\",\n","                \"isn\": \"is\",\n","                \"don\": \"do\",\n","                \"can\": \"ca\"\n","            },\n","            pre_token_chs=\"▁\",\n","        )\n","\n","\n","class ElectraPreprocessor(BertPreprocessorBase):\n","    def __init__(self):\n","        super().__init__(\n","            model=ElectraModel.from_pretrained(\"google/electra-base-discriminator\", output_attentions=True, output_values=True, output_dense=True),\n","            tokenizer=ElectraTokenizer.from_pretrained(\"google/electra-base-discriminator\")\n","        )\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aBeMrA4M6CS0"},"source":["# Applying the preprocessors\n"]},{"cell_type":"markdown","metadata":{"id":"T__GqJ6gcCKA"},"source":["## BERT"]},{"cell_type":"code","metadata":{"id":"ooXVn0fb6cun","colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["2c47860a73574aa880ff8413f9f02055","759c0817890948a2b5322abc822e490e","f70d697376144ee28da179fd85632e19","6a5f47c90d9246fa8be96601698bc32c","fdee922a701841b7944644737c77b0f8","6e3d86eac15e46a4bc714b7c3dfeb3ca","f266fc6956fc4020be8ad7b0d39f4473","04393b4d7c9845328ff09812789baa73","34a3315142a44bb284fcf8d67a8e2a6b","ce68e6c007be470f8301db28de648e9e","ce768037568d4e17a5feb4e34a26bc6d","446f214aad8c440da2c37f070d1aaabd","769dd33ac7fd497693c3c40ad955aeae","5eae51b780604a82b03cb5e76af2d015","ed6dca13e1e74a65b8f59e79b74883a6","33179b70557e4dfca79335d199819cda","6abbe54a29c04bfa84603ff882a7f0a5","06d8de1426ac4327bc00bf12c31b44c1","05d60d7ae5ad433681421786e38ae4ce","9263629278da4bd495ed547dbf7db3ff","98c70d73b3e54e509bded8ade6453720","07e8162a766e46a9831a3df9ca0e1a9f","51dd6529c6cd4ad3b0334a5680aaded3","71ad220c93fd47f9841c309b534d7f38"]},"executionInfo":{"status":"ok","timestamp":1608044611940,"user_tz":-60,"elapsed":68985,"user":{"displayName":"Arnout Hillen","photoUrl":"","userId":"08191576707558497951"}},"outputId":"cfe90ec3-7f7e-43da-863e-234e2e8cc990"},"source":["dataset_b = load_from_disk(\"./drive/My Drive/Datasets/bookcorpus/bookcorpus (1000 samples, train)\")\n","preprocessor_b = BertPreprocessor()\n","#dataset_b = dataset_b.map(preprocessor.add_tokens)\n","#dataset_b = dataset_b.map(preprocessor.add_attention)\n","#dataset_b = dataset_b.map(preprocessor.add_pos_tags)\n","#dataset_b = dataset_b.map(preprocessor.add_value_norms)\n","#dataset_b.save_to_disk(\"./drive/My Drive/Attention/bookcorpus (1000 samples, train)/bert\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c47860a73574aa880ff8413f9f02055","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34a3315142a44bb284fcf8d67a8e2a6b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6abbe54a29c04bfa84603ff882a7f0a5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qGNQvNRI6axn"},"source":["## GPT-2\n"]},{"cell_type":"code","metadata":{"id":"vV93YL_26rLR"},"source":["dataset_g = load_from_disk(\"./drive/My Drive/Datasets/bookcorpus/bookcorpus (1000 samples, train)\")\n","preprocessor_g = GPT2Preprocessor()\n","dataset_g = dataset_g.map(preprocessor.add_tokens)\n","dataset_g = dataset_g.map(preprocessor.add_attention)\n","dataset_g = dataset_g.map(preprocessor.add_pos_tags)\n","dataset_g = dataset_g.map(preprocessor.add_value_norms)\n","dataset_g.save_to_disk(\"./drive/My Drive/Attention/bookcorpus (1000 samples, train)/gpt2\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-hrrJF-G6c5w"},"source":["## XLNet"]},{"cell_type":"code","metadata":{"id":"ZLePGbX66rpS"},"source":["dataset_x = load_from_disk(\"./drive/My Drive/Datasets/bookcorpus/bookcorpus (1000 samples, train)\")\n","preprocessor_x = XLNetPreprocessor()\n","dataset_x = dataset_x.map(preprocessor.add_tokens)\n","dataset_x = dataset_x.map(preprocessor.add_attention)\n","dataset_x = dataset_x.map(preprocessor.add_pos_tags)\n","dataset_x = dataset_x.map(preprocessor.add_value_norms)\n","dataset_x.save_to_disk(\"./drive/My Drive/Attention/bookcorpus (1000 samples, train)/xlnet\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TPjnaCg96c-S"},"source":["## ELECTRA\n"]},{"cell_type":"code","metadata":{"id":"goNv7IS06sIi"},"source":["dataset_e = load_from_disk(\"./drive/My Drive/Datasets/bookcorpus/bookcorpus (1000 samples, train)\")\n","preprocessor_e = ElectraPreprocessor()\n","dataset_e = dataset_e.map(preprocessor.add_tokens)\n","dataset_e = dataset_e.map(preprocessor.add_attention)\n","dataset_e = dataset_e.map(preprocessor.add_pos_tags)\n","dataset_e = dataset_e.map(preprocessor.add_value_norms)\n","dataset_e.save_to_disk(\"./drive/My Drive/Attention/bookcorpus (1000 samples, train)/electra\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s96_BIeXGDpi"},"source":["# A look at the datasets"]},{"cell_type":"code","metadata":{"id":"Ycfk4288GYL4"},"source":["sample = 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31zb8oh9GHJf"},"source":["## BERT"]},{"cell_type":"code","metadata":{"id":"lx3uPhBLGKk5"},"source":["dataset_sample = dataset_b[sample]\n","print(\"text\", dataset_sample[\"text\"])\n","print(\"tokens\", dataset_sample[\"tokens\"])\n","print(\"pos\" ,dataset_sample[\"pos\"])\n","print(\"attention\", np.array(dataset_sample[\"attention\"]).shape)\n","print(\"value norms\", np.array(dataset_sample[\"value_norms\"]).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qTS7pyG6GHNG"},"source":["## GPT-2"]},{"cell_type":"code","metadata":{"id":"WSQ8I3ARGLNi"},"source":["dataset_sample = dataset_g[sample]\n","print(\"text\", dataset_sample[\"text\"], sep=\"\\t\")\n","print(\"tokens\", dataset_sample[\"tokens\"], sep=\"\\t\")\n","print(\"pos\" ,dataset_sample[\"pos\"], sep=\"\\t\")\n","print(\"attention\", np.array(dataset_sample[\"attention\"]).shape)\n","print(\"value norms\", np.array(dataset_sample[\"value_norms\"]).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2mdZ-3aDGHRA"},"source":["## XLNet"]},{"cell_type":"code","metadata":{"id":"Me_DKrKbGLvb"},"source":["dataset_sample = dataset_x[sample]\n","print(\"text\", dataset_sample[\"text\"], sep=\"\\t\")\n","print(\"tokens\", dataset_sample[\"tokens\"], sep=\"\\t\")\n","print(\"pos\" ,dataset_sample[\"pos\"], sep=\"\\t\")\n","print(\"attention\", np.array(dataset_sample[\"attention\"]).shape)\n","print(\"value norms\", np.array(dataset_sample[\"value_norms\"]).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XPJ70YFdGHU6"},"source":["## ELECTRA"]},{"cell_type":"code","metadata":{"id":"GnGcb_HUGMRA"},"source":["dataset_sample = dataset_e[sample]\n","print(\"text\", dataset_sample[\"text\"], sep=\"\\t\")\n","print(\"tokens\", dataset_sample[\"tokens\"], sep=\"\\t\")\n","print(\"pos\" ,dataset_sample[\"pos\"], sep=\"\\t\")\n","print(\"attention\", np.array(dataset_sample[\"attention\"]).shape)\n","print(\"value norms\", np.array(dataset_sample[\"value_norms\"]).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKlTKguKxsTY","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"error","timestamp":1608055154139,"user_tz":-60,"elapsed":700,"user":{"displayName":"Arnout Hillen","photoUrl":"","userId":"08191576707558497951"}},"outputId":"e4b41207-9c2c-461b-9e32-5c7186a7fc54"},"source":["row = 0\n","inputs = preprocessor_b.tokenizer(dataset_b[row][\"text\"], return_tensors=\"pt\")\n","outputs = preprocessor_b.model(**inputs)\n","values = outputs[\"values\"]\n","values = torch.stack(values).squeeze()\n","values = values.detach()\n","dense = outputs[\"dense\"]\n","print(values.shape)\n","\n","all_head_size = 12 * 64\n","num_attention_heads = 12\n","attention_head_size = 64\n","\n","# dense weight is converted to (num_heads, head_size, all_head_size)\n","# dense = torch.tensor([dense[i].view()])\n","\n","dense_t = dense_t.view(all_head_size, num_attention_heads, attention_head_size)\n","dense_t = dense_t.permute(1, 2, 0).contiguous()\n","print(type(dense_t))\n","print(dense_t.shape)\n","print(torch.einsum(\"lhtd,hde->lhte\", ).shape)\n","\n","norms = np.linalg.norm(values, axis=-1)\n"],"execution_count":49,"outputs":[{"output_type":"stream","text":["torch.Size([12, 12, 35, 64])\n","<class 'torch.Tensor'>\n","torch.Size([12, 64, 768])\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-86113f58882c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lhtd,hde->lhte\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mnorms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: more operands in equation than tensors"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axCn9UBE7fdv","executionInfo":{"status":"ok","timestamp":1608046406533,"user_tz":-60,"elapsed":735,"user":{"displayName":"Arnout Hillen","photoUrl":"","userId":"08191576707558497951"}},"outputId":"6118d280-b1f2-4f88-e2d8-37b4e057a8be"},"source":["# attention_probs: (batch, num_heads, seq_length, seq_length)\n","# value_layer: (batch, num_heads, seq_length, head_size)\n","# dense: nn.Linear(all_head_size, all_head_size)\n","\n","inputs = preprocessor_b.tokenizer(dataset_b[row][\"text\"], return_tensors=\"pt\")\n","outputs = preprocessor_b.model(**inputs)\n","values = outputs[\"values\"]\n","values = torch.stack(values).squeeze()\n","values = values.detach()\n","dense = outputs[\"dense\"]\n","\n","value_layer = value_layer.permute(0, 2, 1, 3).contiguous()\n","value_shape = value_layer.size()\n","value_layer = value_layer.view(value_shape[:-1] + (1, value_shape[-1],))\n","\n","# dense weight is converted to (num_heads, head_size, all_head_size)\n","dense = dense.weight\n","dense = dense.view(self.all_head_size, self.num_attention_heads, self.attention_head_size)\n","dense = dense.permute(1, 2, 0).contiguous()\n","\n","# Make transformed vectors f(x) from Value vectors (value_layer) and weight matrix (dense).\n","transformed_layer = value_layer.matmul(dense)\n","transformed_shape = transformed_layer.size() #(batch, seq_length, num_heads, 1, all_head_size)\n","transformed_layer = transformed_layer.view(transformed_shape[:-2] + (transformed_shape[-1],))\n","transformed_layer = transformed_layer.permute(0, 2, 1, 3).contiguous() \n","transformed_shape = transformed_layer.size() #(batch, num_heads, seq_length, all_head_size)\n","transformed_norm = torch.norm(transformed_layer, dim=-1)\n","\n","# Make weighted vectors αf(x) from transformed vectors (transformed_layer) and attention weights (attention_probs).\n","weighted_layer = torch.einsum('bhks,bhsd->bhksd', attention_probs, transformed_layer) #(batch, num_heads, seq_length, seq_length, all_head_size)\n","weighted_norm = torch.norm(weighted_layer, dim=-1)\n","\n","# Sum each αf(x) over all heads: (batch, seq_length, seq_length, all_head_size)\n","summed_weighted_layer = weighted_layer.sum(dim=1)\n","\n","# Calculate L2 norm of summed weighted vectors: (batch, seq_length, seq_length)\n","summed_weighted_norm = torch.norm(summed_weighted_layer, dim=-1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ 0  1  2]\n"," [ 3  4  5]\n"," [ 6  7  8]\n"," [ 9 10 11]]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"4_-UAx9gCEg_"},"source":[""],"execution_count":null,"outputs":[]}]}